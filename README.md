# ğŸ‘‹Hello there:)

I am Kaiyuan Liu a **M.Sc. student in Data Science** at the **University of Macau**. My research interests include **Large Language Models (LLMs)**, **On-Device Inference**, **Edge Computing**, and **MLSys**.

## ğŸ“š Research

I work on bridging the gap between **high-performance AI systems** and **resource-constrained environments**, such as mobile and edge devices. Below are some of my recent publications:

## ğŸ“š ä»£è¡¨æ€§æˆæœ

### HCInferï¼šè¾¹ç¼˜è®¾å¤‡ä¸Šå¤§è¯­è¨€æ¨¡å‹çš„å±‚æ¬¡ååŒæ¨ç†æ¡†æ¶

<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="fig.1" alt="HCInfer" style="width: 200px; height: auto; margin-right: 20px;">
  <div>
    <p><strong>ä¼šè®®ï¼š</strong>IEEE å®æ—¶ç³»ç»Ÿç ”è®¨ä¼šï¼ˆRTSSâ€™25ï¼ŒCCF-Aï¼‰</p>
    <p><strong>åˆä½œè€…ï¼š</strong>å¼ ä¸½å­ã€è®¸æˆå¿ ã€æåŠ›</p>
    <p><strong>äº®ç‚¹ï¼š</strong>æå‡ºäº†ä¸€ç§å±‚æ¬¡åŒ–ååŒæ¨ç†æ¡†æ¶ï¼Œåˆ©ç”¨é‚»è¿‘è®¾å¤‡çš„ç©ºé—²èµ„æºï¼Œå®ç°å¤§è¯­è¨€æ¨¡å‹çš„å®æ—¶æ¨ç†ã€‚</p>
  </div>
</div>

### m2LLMï¼šç§»åŠ¨è®¾å¤‡ä¸Šå¤§è¯­è¨€æ¨¡å‹æ¨ç†çš„å¤šç»´ä¼˜åŒ–æ¡†æ¶

<div style="display: flex; align-items: center; margin-bottom: 20px;">
  <img src="fig.2" alt="m2LLM" style="width: 200px; height: auto; margin-right: 20px;">
  <div>
    <p><strong>æœŸåˆŠï¼š</strong>IEEE å¹¶è¡Œä¸åˆ†å¸ƒå¼ç³»ç»Ÿæ±‡åˆŠï¼ˆTPDSâ€™25ï¼ŒCCF-Aï¼‰</p>
    <p><strong>åˆä½œè€…ï¼š</strong>å‘¨æ™“åšã€æåŠ›</p>
    <p><strong>äº®ç‚¹ï¼š</strong>æå‡ºäº†ä¸€ç§å¤šç»´åº¦ä¼˜åŒ–æ¡†æ¶ï¼Œå¹³è¡¡äº†æ€§èƒ½ã€å®æ—¶æ€§å’Œèƒ½æ•ˆï¼Œæå‡äº†ç§»åŠ¨è®¾å¤‡ä¸Šå¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†æ•ˆç‡ã€‚</p>
  </div>
</div>


## ğŸ§‘â€ğŸ’» Research Experience

### **Edge LLM Collaborative Inference Framework**  
*University of Macau, Jan. 2025 â€“ May. 2025*  
This project focuses on developing a **collaborative inference framework** using idle neighboring devices to address **memory and compute constraints** in edge-device LLM deployment. We employ two-level optimization: **inter-device coordination** and **intra-device resource utilization**.

### **LLM Inference on Mobile Devices**  
*University of Macau, Jun. 2024 â€“ Dec. 2024*  
I am investigating ways to optimize **LLM inference** on mobile devices, addressing issues like high energy consumption and long inference times. The framework incorporates **multi-dimensional optimization** to balance performance, real-time efficiency, and energy consumption.

![Mobile LLM](fig.3)  <!-- Replace with an actual image related to Mobile LLM -->

### **Chinese Sign Language Recognition Project**  
*Henan University, Apr. 2021 â€“ May. 2022*  
I led the development of a **Chinese Sign Language recognition model** that achieved 88% accuracy for 300 signs. This project won the **National Innovation and Entrepreneurship Training** award and contributed to one software copyright.

## ğŸ† Awards & Honors
- **Outstanding Graduate**, Henan University (Top 10%), 2023
- **Henan University Scholarship** (Top 10%), 2022 & 2023
- **Provincial 1st Prize**, CUMCM, Henan Province, 2021

## ğŸ“¬ Contact Me
- **Email**: [kaiyuanliu@um.edu.mo](mailto:kaiyuanliu@um.edu.mo)
- **GitHub**: [github.com/username](https://github.com/username)
- **Homepage**: [your-personal-website-link](#)

Feel free to explore my repositories, or contact me if you're interested in collaboration, research discussions, or AI-related topics!

---

> *"The future is not something we enter. The future is something we create."* â€” **Leonard I. Sweet**

